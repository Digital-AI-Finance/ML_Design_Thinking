% Pandoc LaTeX template for course handouts
% Usage: pandoc input.md -o output.tex --template=handout_template.tex --listings
\documentclass[10pt,a4paper]{article}

% Geometry
\usepackage[margin=2.5cm]{geometry}

% Fonts and encoding
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}

% Math
\usepackage{amsmath,amssymb,amsfonts}

% Tables
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}

% Graphics
\usepackage{graphicx}

% Colors
\usepackage{xcolor}
\definecolor{mlpurple}{RGB}{51,51,178}
\definecolor{mlblue}{RGB}{0,102,204}
\definecolor{codebg}{RGB}{248,248,248}
\definecolor{codeframe}{RGB}{200,200,200}

% Code listings
\usepackage{listings}
\lstset{
  backgroundcolor=\color{codebg},
  basicstyle=\ttfamily\small,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  commentstyle=\color{gray},
  frame=single,
  framerule=0.5pt,
  rulecolor=\color{codeframe},
  keepspaces=true,
  keywordstyle=\color{mlblue}\bfseries,
  language=Python,
  numbers=none,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stringstyle=\color{mlpurple},
  tabsize=4,
  xleftmargin=0.5em,
  xrightmargin=0.5em,
  aboveskip=1em,
  belowskip=1em
}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=mlblue,
  urlcolor=mlblue,
  citecolor=mlblue
}

% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\textcolor{mlpurple}{\textbf{NLP & Sentiment}}}
\rhead{\textcolor{gray}{Advanced}}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% Paragraph spacing
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.5em}

% Section formatting
\usepackage{titlesec}
\titleformat{\section}
  {\Large\bfseries\color{mlpurple}}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\large\bfseries\color{mlblue}}
  {\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalsize\bfseries}
  {\thesubsubsection}{1em}{}

% Lists
\usepackage{enumitem}
\setlist[itemize]{topsep=0.5em, itemsep=0.25em}
\setlist[enumerate]{topsep=0.5em, itemsep=0.25em}

% Tight list support for pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Title
\title{\Huge\bfseries\color{mlpurple} Handout 3: Aspect-Based Sentiment & Emotion Detection (Advanced Level)}
\author{Machine Learning for Smarter Innovation}
\date{}

\begin{document}

\maketitle
\thispagestyle{fancy}

\section{Handout 3: Aspect-Based Sentiment \& Emotion Detection
(Advanced
Level)}\label{handout-3-aspect-based-sentiment-emotion-detection-advanced-level}

\subsection{Week 3 - Advanced NLP Techniques for Deep User
Understanding}\label{week-3---advanced-nlp-techniques-for-deep-user-understanding}

\subsubsection{Introduction to Aspect-Based Sentiment Analysis
(ABSA)}\label{introduction-to-aspect-based-sentiment-analysis-absa}

Traditional sentiment analysis tells us if a review is positive or
negative overall. ABSA goes deeper, identifying sentiment for specific
aspects of a product or service.

Example: - \textbf{Overall}: ``Mixed feelings about this laptop'' →
Neutral - \textbf{Aspect-based}: - Performance: ``blazing fast
processor'' → Positive - Battery: ``dies after 2 hours'' → Negative -
Design: ``sleek and professional'' → Positive - Price: ``overpriced for
the specs'' → Negative

\subsubsection{Multi-Aspect Sentiment Analysis
Implementation}\label{multi-aspect-sentiment-analysis-implementation}

\paragraph{Aspect Extraction}\label{aspect-extraction}

\begin{lstlisting}[language=Python]
import spacy
from transformers import pipeline
import pandas as pd

class AspectSentimentAnalyzer:
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        self.sentiment_analyzer = pipeline("sentiment-analysis")
        self.aspect_keywords = {
            'performance': ['fast', 'slow', 'speed', 'quick', 'lag', 'smooth'],
            'battery': ['battery', 'charge', 'power', 'lasting'],
            'display': ['screen', 'display', 'brightness', 'resolution'],
            'price': ['price', 'cost', 'expensive', 'cheap', 'value', 'worth'],
            'quality': ['build', 'quality', 'durable', 'solid', 'flimsy'],
            'design': ['design', 'look', 'aesthetic', 'beautiful', 'ugly'],
            'support': ['support', 'service', 'help', 'response'],
        }
    
    def extract_aspects(self, text):
        """Extract aspect-specific sentences from text."""
        doc = self.nlp(text)
        aspect_sentences = {aspect: [] for aspect in self.aspect_keywords}
        
        for sent in doc.sents:
            sent_text = sent.text.lower()
            for aspect, keywords in self.aspect_keywords.items():
                if any(keyword in sent_text for keyword in keywords):
                    aspect_sentences[aspect].append(sent.text)
        
        return aspect_sentences
    
    def analyze_aspect_sentiment(self, text):
        """Analyze sentiment for each aspect in the text."""
        aspect_sentences = self.extract_aspects(text)
        aspect_sentiments = {}
        
        for aspect, sentences in aspect_sentences.items():
            if sentences:
                # Analyze sentiment for each sentence
                sentiments = []
                for sentence in sentences:
                    result = self.sentiment_analyzer(sentence)[0]
                    sentiments.append({
                        'sentence': sentence,
                        'sentiment': result['label'],
                        'score': result['score']
                    })
                
                # Aggregate sentiment for the aspect
                avg_score = sum(s['score'] if s['sentiment'] == 'POSITIVE' else -s['score'] 
                              for s in sentiments) / len(sentiments)
                
                aspect_sentiments[aspect] = {
                    'overall_sentiment': 'positive' if avg_score > 0 else 'negative',
                    'confidence': abs(avg_score),
                    'details': sentiments
                }
        
        return aspect_sentiments
\end{lstlisting}

\paragraph{Advanced Aspect Extraction with Dependency
Parsing}\label{advanced-aspect-extraction-with-dependency-parsing}

\begin{lstlisting}[language=Python]
def extract_aspect_opinion_pairs(text):
    """Extract aspect-opinion pairs using dependency parsing."""
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(text)
    
    aspect_opinion_pairs = []
    
    for token in doc:
        # Find adjectives (opinions)
        if token.pos_ == "ADJ":
            # Find the aspect (noun) it modifies
            for child in token.children:
                if child.pos_ == "NOUN":
                    aspect_opinion_pairs.append({
                        'aspect': child.text,
                        'opinion': token.text,
                        'sentiment': analyze_opinion_sentiment(token.text)
                    })
            
            # Check if adjective modifies a noun through 'amod' relation
            if token.dep_ == "amod" and token.head.pos_ == "NOUN":
                aspect_opinion_pairs.append({
                    'aspect': token.head.text,
                    'opinion': token.text,
                    'sentiment': analyze_opinion_sentiment(token.text)
                })
    
    return aspect_opinion_pairs

def analyze_opinion_sentiment(opinion):
    """Simple sentiment scoring for opinion words."""
    positive_opinions = ['good', 'great', 'excellent', 'amazing', 'fast', 'beautiful']
    negative_opinions = ['bad', 'poor', 'terrible', 'slow', 'ugly', 'broken']
    
    if opinion.lower() in positive_opinions:
        return 'positive'
    elif opinion.lower() in negative_opinions:
        return 'negative'
    else:
        return 'neutral'
\end{lstlisting}

\subsubsection{Emotion Classification: Beyond
Positive/Negative}\label{emotion-classification-beyond-positivenegative}

\paragraph{8-Emotion Classification
System}\label{emotion-classification-system}

\begin{lstlisting}[language=Python]
from transformers import pipeline

class EmotionDetector:
    def __init__(self):
        # Using a model trained on 8 emotions
        self.classifier = pipeline(
            "text-classification",
            model="j-hartmann/emotion-english-distilroberta-base",
            return_all_scores=True
        )
        self.emotions = ['anger', 'disgust', 'fear', 'joy', 
                        'neutral', 'sadness', 'surprise', 'shame']
    
    def detect_emotions(self, text):
        """Detect multiple emotions with confidence scores."""
        results = self.classifier(text)[0]
        
        # Sort by score
        emotions = sorted(results, key=lambda x: x['score'], reverse=True)
        
        # Get primary and secondary emotions
        primary = emotions[0]
        secondary = emotions[1] if emotions[1]['score'] > 0.2 else None
        
        return {
            'primary_emotion': primary['label'],
            'primary_confidence': primary['score'],
            'secondary_emotion': secondary['label'] if secondary else None,
            'secondary_confidence': secondary['score'] if secondary else 0,
            'all_emotions': {e['label']: e['score'] for e in emotions}
        }
    
    def analyze_emotional_journey(self, reviews_timeline):
        """Track emotion evolution over time."""
        journey = []
        
        for timestamp, review in reviews_timeline:
            emotions = self.detect_emotions(review)
            journey.append({
                'timestamp': timestamp,
                'text': review,
                'emotion': emotions['primary_emotion'],
                'confidence': emotions['primary_confidence']
            })
        
        return pd.DataFrame(journey)
\end{lstlisting}

\paragraph{Multi-Label Emotion
Detection}\label{multi-label-emotion-detection}

\begin{lstlisting}[language=Python]
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class MultiEmotionDetector:
    def __init__(self, threshold=0.3):
        self.threshold = threshold
        model_name = "SamLowe/roberta-base-go_emotions"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        # 28 emotions from GoEmotions dataset
        self.emotions = [
            'admiration', 'amusement', 'anger', 'annoyance', 'approval',
            'caring', 'confusion', 'curiosity', 'desire', 'disappointment',
            'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',
            'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',
            'pride', 'realization', 'relief', 'remorse', 'sadness',
            'surprise', 'neutral'
        ]
    
    def detect_multiple_emotions(self, text):
        """Detect multiple co-occurring emotions."""
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            scores = torch.sigmoid(outputs.logits).squeeze().tolist()
        
        # Get emotions above threshold
        detected_emotions = []
        for emotion, score in zip(self.emotions, scores):
            if score > self.threshold:
                detected_emotions.append({
                    'emotion': emotion,
                    'confidence': score
                })
        
        return sorted(detected_emotions, key=lambda x: x['confidence'], reverse=True)
\end{lstlisting}

\subsubsection{Sarcasm and Irony
Detection}\label{sarcasm-and-irony-detection}

\paragraph{Rule-Based + ML Hybrid
Approach}\label{rule-based-ml-hybrid-approach}

\begin{lstlisting}[language=Python]
class SarcasmDetector:
    def __init__(self):
        self.sentiment_analyzer = pipeline("sentiment-analysis")
        self.sarcasm_indicators = [
            'yeah right', 'sure', 'oh great', 'wonderful', 'fantastic',
            'brilliant', 'genius', 'obviously', 'clearly'
        ]
        self.punctuation_patterns = ['!!!', '...', '?!', '!?']
        
    def detect_sarcasm(self, text, context=None):
        """Detect sarcasm using multiple signals."""
        text_lower = text.lower()
        sarcasm_score = 0
        
        # Check for sarcasm indicators
        for indicator in self.sarcasm_indicators:
            if indicator in text_lower:
                sarcasm_score += 0.3
        
        # Check for excessive punctuation
        for pattern in self.punctuation_patterns:
            if pattern in text:
                sarcasm_score += 0.2
        
        # Check for contradiction between words and sentiment
        if any(word in text_lower for word in ['love', 'great', 'amazing']):
            sentiment = self.sentiment_analyzer(text)[0]
            # If positive words but overall negative context
            if context and 'complaint' in context.lower():
                sarcasm_score += 0.4
        
        # Check for quotation marks around positive words
        import re
        quoted_positives = re.findall(r'"([^"]*)"', text)
        for quote in quoted_positives:
            if any(pos in quote.lower() for pos in ['great', 'wonderful', 'amazing']):
                sarcasm_score += 0.3
        
        return {
            'is_sarcastic': sarcasm_score > 0.5,
            'confidence': min(sarcasm_score, 1.0),
            'indicators_found': self._get_found_indicators(text_lower)
        }
    
    def _get_found_indicators(self, text_lower):
        """Return which sarcasm indicators were found."""
        return [ind for ind in self.sarcasm_indicators if ind in text_lower]
\end{lstlisting}

\paragraph{Deep Learning Sarcasm
Detection}\label{deep-learning-sarcasm-detection}

\begin{lstlisting}[language=Python]
from transformers import pipeline

def advanced_sarcasm_detection(texts):
    """Use a fine-tuned model for sarcasm detection."""
    # Load sarcasm detection model
    sarcasm_model = pipeline(
        "text-classification",
        model="mrm8488/t5-base-finetuned-sarcasm-twitter"
    )
    
    results = []
    for text in texts:
        prediction = sarcasm_model(text)[0]
        
        # Adjust interpretation based on context
        if prediction['label'] == 'SARCASM':
            # Double-check with sentiment analysis
            sentiment = pipeline("sentiment-analysis")(text)[0]
            
            # High confidence sarcasm if positive words but sarcasm detected
            contains_positive = any(word in text.lower() 
                                  for word in ['great', 'love', 'amazing', 'wonderful'])
            
            confidence = prediction['score']
            if contains_positive:
                confidence = min(confidence * 1.2, 1.0)
            
            results.append({
                'text': text,
                'is_sarcastic': True,
                'confidence': confidence,
                'implied_sentiment': 'negative' if sentiment['label'] == 'POSITIVE' else 'positive'
            })
        else:
            results.append({
                'text': text,
                'is_sarcastic': False,
                'confidence': prediction['score'],
                'implied_sentiment': None
            })
    
    return results
\end{lstlisting}

\subsubsection{Building Production
Pipelines}\label{building-production-pipelines}

\paragraph{Complete NLP Pipeline}\label{complete-nlp-pipeline}

\begin{lstlisting}[language=Python]
class ProductionNLPPipeline:
    def __init__(self):
        self.aspect_analyzer = AspectSentimentAnalyzer()
        self.emotion_detector = EmotionDetector()
        self.sarcasm_detector = SarcasmDetector()
        
    def full_analysis(self, text, user_context=None):
        """Complete analysis pipeline for production."""
        
        # 1. Preprocess
        cleaned_text = self.preprocess(text)
        
        # 2. Detect sarcasm first (affects interpretation)
        sarcasm = self.sarcasm_detector.detect_sarcasm(cleaned_text, user_context)
        
        # 3. Aspect-based sentiment
        aspects = self.aspect_analyzer.analyze_aspect_sentiment(cleaned_text)
        
        # 4. Emotion detection
        emotions = self.emotion_detector.detect_emotions(cleaned_text)
        
        # 5. Adjust interpretations if sarcastic
        if sarcasm['is_sarcastic']:
            aspects = self.invert_sentiments(aspects)
            emotions = self.adjust_emotions_for_sarcasm(emotions)
        
        # 6. Generate insights
        insights = self.generate_insights(aspects, emotions, sarcasm)
        
        return {
            'original_text': text,
            'preprocessed_text': cleaned_text,
            'sarcasm': sarcasm,
            'aspects': aspects,
            'emotions': emotions,
            'insights': insights,
            'priority_score': self.calculate_priority(aspects, emotions)
        }
    
    def preprocess(self, text):
        """Clean and prepare text for analysis."""
        # Remove URLs, mentions, etc.
        import re
        text = re.sub(r'http\S+', '', text)
        text = re.sub(r'@\w+', '', text)
        text = re.sub(r'#(\w+)', r'\1', text)  # Keep hashtag content
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def invert_sentiments(self, aspects):
        """Invert sentiments if sarcasm detected."""
        inverted = {}
        for aspect, data in aspects.items():
            inverted[aspect] = data.copy()
            if data['overall_sentiment'] == 'positive':
                inverted[aspect]['overall_sentiment'] = 'negative'
                inverted[aspect]['sarcasm_adjusted'] = True
            elif data['overall_sentiment'] == 'negative':
                inverted[aspect]['overall_sentiment'] = 'positive'
                inverted[aspect]['sarcasm_adjusted'] = True
        return inverted
    
    def adjust_emotions_for_sarcasm(self, emotions):
        """Adjust emotion detection for sarcastic text."""
        # Sarcasm often indicates frustration or anger
        adjusted = emotions.copy()
        if emotions['primary_emotion'] == 'joy':
            adjusted['primary_emotion'] = 'anger'
            adjusted['sarcasm_adjusted'] = True
        return adjusted
    
    def generate_insights(self, aspects, emotions, sarcasm):
        """Generate actionable insights from analysis."""
        insights = []
        
        # Critical issues (negative sentiment + strong emotion)
        for aspect, sentiment_data in aspects.items():
            if sentiment_data.get('overall_sentiment') == 'negative':
                if sentiment_data.get('confidence', 0) > 0.8:
                    insights.append({
                        'type': 'critical_issue',
                        'aspect': aspect,
                        'action': f'Urgent attention needed for {aspect}',
                        'emotion': emotions['primary_emotion']
                    })
        
        # Sarcasm detection insight
        if sarcasm['is_sarcastic']:
            insights.append({
                'type': 'user_frustration',
                'indicator': 'Sarcasm detected',
                'action': 'User likely frustrated despite positive words'
            })
        
        # Emotional state insights
        if emotions['primary_emotion'] in ['anger', 'disgust', 'fear']:
            insights.append({
                'type': 'negative_emotion',
                'emotion': emotions['primary_emotion'],
                'action': 'Immediate response recommended'
            })
        
        return insights
    
    def calculate_priority(self, aspects, emotions):
        """Calculate priority score for response."""
        score = 0
        
        # Negative aspects increase priority
        negative_aspects = sum(1 for a in aspects.values() 
                              if a.get('overall_sentiment') == 'negative')
        score += negative_aspects * 20
        
        # Strong negative emotions increase priority
        if emotions['primary_emotion'] in ['anger', 'disgust']:
            score += 30
        elif emotions['primary_emotion'] in ['sadness', 'fear']:
            score += 20
        
        # High confidence increases priority
        if emotions['primary_confidence'] > 0.9:
            score += 10
        
        return min(score, 100)  # Cap at 100
\end{lstlisting}

\paragraph{Batch Processing with
Caching}\label{batch-processing-with-caching}

\begin{lstlisting}[language=Python]
import hashlib
import json
import redis

class CachedSentimentAnalyzer:
    def __init__(self, redis_host='localhost', redis_port=6379):
        self.pipeline = ProductionNLPPipeline()
        self.cache = redis.Redis(host=redis_host, port=redis_port, db=0)
        self.cache_ttl = 86400  # 24 hours
    
    def analyze_with_cache(self, text):
        """Analyze text with caching for efficiency."""
        # Generate cache key
        cache_key = hashlib.md5(text.encode()).hexdigest()
        
        # Check cache
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # Analyze if not cached
        result = self.pipeline.full_analysis(text)
        
        # Store in cache
        self.cache.setex(
            cache_key,
            self.cache_ttl,
            json.dumps(result, default=str)
        )
        
        return result
    
    def batch_analyze(self, texts, batch_size=32):
        """Efficiently process large batches."""
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            
            # Process batch in parallel (simplified)
            batch_results = [self.analyze_with_cache(text) for text in batch]
            results.extend(batch_results)
            
            # Log progress
            print(f"Processed {min(i+batch_size, len(texts))}/{len(texts)}")
        
        return results
\end{lstlisting}

\subsubsection{Real-World Application: Customer Feedback
Analysis}\label{real-world-application-customer-feedback-analysis}

\begin{lstlisting}[language=Python]
class CustomerFeedbackAnalyzer:
    def __init__(self):
        self.pipeline = ProductionNLPPipeline()
    
    def analyze_product_feedback(self, reviews_df):
        """Comprehensive analysis of product reviews."""
        results = {
            'aspect_summary': {},
            'emotion_distribution': {},
            'critical_issues': [],
            'positive_highlights': [],
            'improvement_suggestions': []
        }
        
        for _, review in reviews_df.iterrows():
            analysis = self.pipeline.full_analysis(review['text'])
            
            # Aggregate aspect sentiments
            for aspect, data in analysis['aspects'].items():
                if aspect not in results['aspect_summary']:
                    results['aspect_summary'][aspect] = {'positive': 0, 'negative': 0}
                
                if data['overall_sentiment'] == 'positive':
                    results['aspect_summary'][aspect]['positive'] += 1
                else:
                    results['aspect_summary'][aspect]['negative'] += 1
            
            # Track emotions
            emotion = analysis['emotions']['primary_emotion']
            results['emotion_distribution'][emotion] = \
                results['emotion_distribution'].get(emotion, 0) + 1
            
            # Identify critical issues
            if analysis['priority_score'] > 70:
                results['critical_issues'].append({
                    'review': review['text'][:200],
                    'aspects': list(analysis['aspects'].keys()),
                    'emotion': emotion,
                    'priority': analysis['priority_score']
                })
        
        # Generate improvement suggestions
        for aspect, counts in results['aspect_summary'].items():
            if counts['negative'] > counts['positive']:
                results['improvement_suggestions'].append({
                    'aspect': aspect,
                    'negative_ratio': counts['negative'] / (counts['negative'] + counts['positive']),
                    'recommendation': f"Focus on improving {aspect} - {counts['negative']} negative mentions"
                })
        
        return results
    
    def generate_report(self, analysis_results):
        """Generate executive summary from analysis."""
        report = []
        report.append("# Customer Feedback Analysis Report\n")
        
        # Aspect Summary
        report.append("## Aspect Performance\n")
        for aspect, counts in analysis_results['aspect_summary'].items():
            total = counts['positive'] + counts['negative']
            if total > 0:
                satisfaction = counts['positive'] / total * 100
                report.append(f"- **{aspect}**: {satisfaction:.1f}% satisfaction "
                            f"({counts['positive']} positive, {counts['negative']} negative)\n")
        
        # Emotion Distribution
        report.append("\n## Emotional Response\n")
        total_reviews = sum(analysis_results['emotion_distribution'].values())
        for emotion, count in sorted(analysis_results['emotion_distribution'].items(), 
                                    key=lambda x: x[1], reverse=True):
            percentage = count / total_reviews * 100
            report.append(f"- {emotion}: {percentage:.1f}% ({count} reviews)\n")
        
        # Critical Issues
        report.append("\n## Critical Issues Requiring Attention\n")
        for issue in analysis_results['critical_issues'][:5]:  # Top 5
            report.append(f"- Priority {issue['priority']}: {issue['review']}\n")
            report.append(f"  - Aspects: {', '.join(issue['aspects'])}\n")
            report.append(f"  - Emotion: {issue['emotion']}\n")
        
        # Recommendations
        report.append("\n## Recommendations\n")
        for suggestion in analysis_results['improvement_suggestions']:
            report.append(f"- {suggestion['recommendation']}\n")
        
        return ''.join(report)
\end{lstlisting}

\subsubsection{Practice Exercise: Complete Sentiment
System}\label{practice-exercise-complete-sentiment-system}

Build an end-to-end sentiment analysis system:

\begin{lstlisting}[language=Python]
# Assignment: Build a comprehensive feedback analyzer
class CompleteFeedbackSystem:
    """
    Your task:
    1. Implement aspect extraction for your domain
    2. Add emotion detection
    3. Include sarcasm detection
    4. Create priority scoring
    5. Generate actionable insights
    6. Build API endpoint
    7. Add monitoring and logging
    """
    
    def __init__(self, domain='general'):
        # Initialize your components
        pass
    
    def analyze(self, text):
        # Implement complete analysis
        pass
    
    def generate_insights(self, analysis):
        # Convert analysis to actionable insights
        pass
    
    def create_dashboard_data(self, batch_results):
        # Prepare data for visualization
        pass

# Test with real data
if __name__ == "__main__":
    system = CompleteFeedbackSystem(domain='e-commerce')
    
    # Test cases
    test_reviews = [
        "Love the camera quality but the battery life is terrible!",
        "Oh great, another 'premium' phone that crashes every hour. Fantastic!",
        "The display is gorgeous, performance is smooth, but way overpriced.",
        "Worst purchase ever. Screen broke on day 2. Support was useless.",
        "Exceeds expectations! Fast delivery, great packaging, product works perfectly."
    ]
    
    for review in test_reviews:
        analysis = system.analyze(review)
        print(f"\nReview: {review}")
        print(f"Analysis: {analysis}")
        print(f"Insights: {system.generate_insights(analysis)}")
\end{lstlisting}

\subsubsection{Best Practices for
Production}\label{best-practices-for-production}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Performance Optimization}

  \begin{itemize}
  \tightlist
  \item
    Use model quantization for faster inference
  \item
    Implement caching for repeated queries
  \item
    Batch process when possible
  \end{itemize}
\item
  \textbf{Accuracy Improvement}

  \begin{itemize}
  \tightlist
  \item
    Combine multiple models for consensus
  \item
    Use domain-specific fine-tuning
  \item
    Implement confidence thresholds
  \end{itemize}
\item
  \textbf{Monitoring}

  \begin{itemize}
  \tightlist
  \item
    Track model drift over time
  \item
    Log edge cases for retraining
  \item
    Monitor response times
  \end{itemize}
\item
  \textbf{Error Handling}

  \begin{itemize}
  \tightlist
  \item
    Graceful degradation for failures
  \item
    Fallback to simpler models
  \item
    Human-in-the-loop for low confidence
  \end{itemize}
\end{enumerate}

\subsubsection{Resources}\label{resources}

\begin{itemize}
\tightlist
\item
  Aspect-Based Sentiment Papers: https://arxiv.org/abs/1805.01984
\item
  Emotion Detection Datasets:
  https://github.com/google-research/google-research/tree/master/goemotions
\item
  Sarcasm Detection: https://arxiv.org/abs/1704.05579
\item
  Production Best Practices: https://mlops.community/
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Remember: The goal is not just to detect sentiment, but to
understand the complete emotional context and generate actionable
insights for better design decisions!}

\end{document}
